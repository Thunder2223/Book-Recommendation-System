# -*- coding: utf-8 -*-
"""Book Recommendation System with Machine Learning Thirunesan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WaHoIV1vDaIKlcZBLpHmo8777bzo1z8M
"""

import os
import shutil
import kagglehub
ruchi798_bookcrossing_dataset_path = kagglehub.dataset_download('ruchi798/bookcrossing-dataset')

print('Data source import complete.')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
books = pd.read_csv('/content/BX_Books.csv', sep=';', encoding="latin-1")
books.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'publisher', 'imageUrlS', 'imageUrlM', 'imageUrlL']

users = pd.read_csv('/content/BX-Users.csv', sep=';', encoding="latin-1")
users.columns = ['userID', 'Location', 'Age']

ratings = pd.read_csv('/content/BX-Book-Ratings.csv', sep=';', encoding="latin-1")
ratings.columns = ['userID', 'ISBN', 'bookRating']

print(ratings.shape)
print(list(ratings.columns))

plt.rc("font", size=15)
ratings.bookRating.value_counts(sort=False).plot(kind='bar')
plt.title('Rating Distribution\n')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()

print(books.shape)
print(list(books.columns))

print(users.shape)
print(list(users.columns))

users.Age.hist(bins=[0, 10, 20, 30, 40, 50, 100])
plt.title('Age Distribution\n')
plt.xlabel('Age')
plt.ylabel('Count')
plt.show()

counts1 = ratings['userID'].value_counts()
ratings = ratings[ratings['userID'].isin(counts1[counts1 >= 200].index)]
counts = ratings['bookRating'].value_counts()
ratings = ratings[ratings['bookRating'].isin(counts[counts >= 100].index)]

combine_book_rating = pd.merge(ratings, books, on='ISBN')
columns = ['yearOfPublication', 'publisher', 'bookAuthor', 'imageUrlS', 'imageUrlM', 'imageUrlL']
combine_book_rating = combine_book_rating.drop(columns, axis=1)
print(combine_book_rating.head())

combine_book_rating = combine_book_rating.dropna(axis = 0, subset = ['bookTitle'])

book_ratingCount = (combine_book_rating.
     groupby(by = ['bookTitle'])['bookRating'].
     count().
     reset_index().
     rename(columns = {'bookRating': 'totalRatingCount'})
     [['bookTitle', 'totalRatingCount']]
    )
print(book_ratingCount.head())

rating_with_totalRatingCount = combine_book_rating.merge(book_ratingCount, left_on = 'bookTitle', right_on = 'bookTitle', how = 'left')
print(rating_with_totalRatingCount.head())

pd.set_option('display.float_format', lambda x: '%.3f' % x)
print(book_ratingCount['totalRatingCount'].describe())

pd.set_option('display.float_format', lambda x: '%.3f' % x)
print(book_ratingCount['totalRatingCount'].describe())

print(book_ratingCount['totalRatingCount'].quantile(np.arange(.9, 1, .01)))

popularity_threshold = 50
rating_popular_book = rating_with_totalRatingCount.query('totalRatingCount >= @popularity_threshold')
print(rating_popular_book.head())

combined = rating_popular_book.merge(users, left_on = 'userID', right_on = 'userID', how = 'left')

us_canada_user_rating = combined[combined['Location'].str.contains("usa|canada")]
us_canada_user_rating=us_canada_user_rating.drop('Age', axis=1)
print(us_canada_user_rating.head())

from scipy.sparse import csr_matrix
us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
us_canada_user_rating_pivot = us_canada_user_rating.pivot(index = 'bookTitle', columns = 'userID', values = 'bookRating').fillna(0)
us_canada_user_rating_matrix = csr_matrix(us_canada_user_rating_pivot.values)

from sklearn.neighbors import NearestNeighbors

model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
model_knn.fit(us_canada_user_rating_matrix)
print(model_knn)

query_index = np.random.choice(us_canada_user_rating_pivot.shape[0])
print(query_index)
print(us_canada_user_rating_pivot.iloc[query_index,:].values.reshape(1,-1))
distances, indices = model_knn.kneighbors(us_canada_user_rating_pivot.iloc[query_index,:].values.reshape(1, -1), n_neighbors = 6)
us_canada_user_rating_pivot.index[query_index]

for i in range(0, len(distances.flatten())):
    if i == 0:
        print('Recommendations for {0}:\n'.format(us_canada_user_rating_pivot.index[query_index]))
    else:
        print('{0}: {1}, with distance of {2}:'.format(i, us_canada_user_rating_pivot.index[indices.flatten()[i]], distances.flatten()[i]))

from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans
ratings_pivot = ratings.pivot(index='userID', columns='ISBN', values='bookRating').fillna(0)

# Applying K-Means clustering
kmeans = KMeans(n_clusters=5, random_state=42)
cluster_labels = kmeans.fit_predict(ratings_pivot)

# Calculating silhouette score
sil_score = silhouette_score(ratings_pivot, cluster_labels)

print(f'Silhouette Score: {sil_score}')

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Assuming the ratings dataset is already loaded and prepared
# Step 1: Pivot ratings data to create user-book ratings matrix
ratings_pivot = ratings.pivot(index='userID', columns='ISBN', values='bookRating').fillna(0)

# Step 2: Elbow Method to find the optimal K
wcss = []
K = range(2, 11)  # Testing for k values from 2 to 10

for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(ratings_pivot)
    wcss.append(kmeans.inertia_)  # WCSS for each k

# Step 3: Plot the WCSS to observe the elbow
plt.figure(figsize=(8, 5))
plt.plot(K, wcss, 'bo-', color='red')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of clusters (k)')
plt.ylabel('WCSS')
plt.show()

# Step 4: Choose the best K based on the elbow (for example, k=5) and calculate silhouette score
optimal_k = 5  # Assuming we determined 5 is the optimal number of clusters

kmeans = KMeans(n_clusters=optimal_k, random_state=42)
cluster_labels = kmeans.fit_predict(ratings_pivot)

# Step 5: Calculate the silhouette score for the chosen k
sil_score = silhouette_score(ratings_pivot, cluster_labels)
print(f'Silhouette Score for k={optimal_k}: {sil_score}')

def accuracy_at_k(actual, predicted, k=5):
    """
    Calculates the accuracy for the top-k recommendations.

    Parameters:
    actual (list): A list of books the user actually liked/rated.
    predicted (list): A list of books predicted/recommended by the model.
    k (int): The number of top recommendations to consider.

    Returns:
    float: Accuracy as the number of hits in the top-k recommendations.
    """
    actual_set = set(actual)
    predicted_set = set(predicted[:k])
    hits = len(actual_set & predicted_set)  # Count hits (correct recommendations)

    # Accuracy = hits / total recommendations (k)
    accuracy = hits / k
    return accuracy

# Example usage:

# Let's say the user actually liked/rated these books
actual_books = ['Book A', 'Book B', 'Book C']  # Actual liked books

# And these are the top-5 books recommended by the system
predicted_books = ['Book D', 'Book A', 'Book C', 'Book E', 'Book B']  # Predicted top-5

# Calculate accuracy for the top-5 recommendations
accuracy = accuracy_at_k(actual_books, predicted_books, k=5)
print(f"Accuracy@5: {accuracy:.2f}")